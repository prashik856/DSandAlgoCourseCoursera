e.g. 
Input: 8 4 2 5 2
 
 -> Find a minimum by scanning the array (2)
 -> Swap it with the first element of array [2| 4 8 5 2]
 -> Repeat with the remaining part of the array.
 -> (2) -> [2 2| 8 5 4] -> (4) -> [2 2 4| 5 8] -> (5) -> [2 2 4 5| 8] -> (8) -> [2 2 4 5 8|]
In the end we have our Sorted array


Psuedo Code:
for i from 1 to n:
    minIndex <- i
    for j from i+1 to n:
        if A[j] < A[minIndex]:
            minIndex <- j
    {A[minIndex] = minA[i...n]} //Sort form
    swap(A[i], A[minIndex])
    {A[1....i] is in final position}


Running time of this sorting algo does not depend on the input data, but it actually depends on the size of input data.

The Running time of SelectionSort is O(n^2)

Proof:
n iterations of outer loop, at most n iterations of inner loop.

Too pessimistic Estimate?
-> As i grows, the number of iterations of the inner loop decreases. j iterates from i+1 to n.
-> More accurate estimate for the totatl number of iterations of the inner loop is: (n-1) + (n-2) + .... + 1
= n^2 - n(n+1)/2 = (2n^2 - n^2 - n)/2 = (n^2 -n)/2 = n(n-1)/2
-> We will show that this sum is O(n^2) implying that our initial estimate is actually right.


Arithmetic series:
Lemma:
1 + 2 + ... + n = n(n+1)/2

Proof:
1 2     .... n
n n-1   .... 1
---------------
n+1 n+1 ..... n+1 = n*(n+1)


Summary:
-> Selection Sort is an easy to implement algorithm with running time O(n^2)
-> Sorts in place: requies a constant amount of extra memory.
-> There are many other quadratic time sorting algorithm e.g. insertion sort, bubble sort.
